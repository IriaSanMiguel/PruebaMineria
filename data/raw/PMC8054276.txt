LA INTELIGENCIA ARTIFICIAL Y SUS APLICACIONES EN MEDICINA I: INTRODUCCIÓN ANTECEDENTES A LA IA Y ROBÓTICA


- INTRODUCCIÓN

La inteligencia artificial (IA) es una rama de las ciencias de la computación que incluye conceptos muy transversales relacionados con la lógica y el aprendizaje. Se trata, por lo tanto, de diseñar herramientas informáticas que simulen procesos de inteligencia humana que incluyen el aprendizaje, el razonamiento y la autocorrección. Mediante diversos algoritmos las máquinas «aprenden» y son capaces de «tomar decisiones». No se trata de ciencia ficción, sino de una realidad que está presente actualmente y que poco a poco va a ir ocupando espacios cotidianos en nuestra casa, en nuestros vehículos y también relacionados con nuestra salud.
La teoría del procesamiento de la información de Mahoney considera al ser humano como un procesador de información a partir de estímulos internos y externos que va almacenando en memoria y que es capaz de elaborar respuestas similares a partir de estímulos posteriores que tengan cierta similitud. Según esta teoría los elementos estructurales en el procesamiento de la información son: registro sensitivo (recepción de información interna y externa), memoria a corto plazo (almacenamiento inmediato de la información seleccionada) y memoria a largo plazo (que organiza y dispone la información durante más tiempo). Además, las categorías del procesamiento son: atención (recibe, selecciona y asimila los diferentes estímulos), codificación (simboliza los estímulos según estructuras mentales propias), almacenamiento (organiza y mantiene en la memoria los símbolos codificados) y recuperación (uso posterior de la información organizada y codificada ante estímulos similares a los que la han ocasionado).
El aprendizaje humano se basaría en la exposición a situaciones repetidas con refuerzos (positivos o negativos) cada vez que tomamos una decisión correcta o erramos. A partir de estímulos similares que tienen soluciones similares y a través de nuestra experiencia y conocimientos previos, empezamos a tomar decisiones. La toma de decisiones supone un pensamiento lógico y jerárquico que puede ser transcrito a algoritmos en un lenguaje que las máquinas pueden interpretar y ejecutar con mucha mayor rapidez que el ser humano.
El aprendizaje humano es progresivo y se desarrolla a partir de la exposición a situaciones de forma consecutiva, proceso que puede llevar años, en cambio, la adquisición de estos datos por parte de una máquina es mucho más rápida, ya que esta no se agota (puede trabajar 24 h al día) y no tiene funciones vitales (alimentación, descanso u ocio). En este sentido las cantidades ingentes de datos en múltiples formatos y fuentes (lo que conocemos como big data), tienen una relación directa con la adquisición de experiencia por parte de las máquinas que se exponen a situaciones o estímulos muy diversos. En este artículo pretendemos dar una visión introductoria de la IA para médicos y realizar un recorrido por las principales aplicaciones en salud que nos ofrece esta tecnología.


- REDES NEURONALES, CEREBRO Y APRENDIZAJE

La base biológica de la inteligencia está en el cerebro. Aunque vamos conociendo cada vez más sobre su fisiología y las diferentes vías anatómicas y funcionales que participan en el proceso de aprendizaje humano, aún existen muchas incógnitas que deben despejarse.
Para las máquinas existe una analogía similar a la estructura y el funcionamiento del cerebro, por lo que es relativamente sencillo establecer esta analogía fácilmente comprensible para los profesionales de la salud.
Las redes neuronales artificiales, en inglés Artificial Neural Networks (ANN) están compuestas por elementos que se comporten de forma similar a la neurona biológica en sus funciones más comunes y que se denominan «elemento procesador», en inglés Process Element (PE). Cada uno de los PE (neuronas) tienen unos elementos de entrada (dendritas) que recogen los impulsos de entrada que son integrados en el cuerpo del elemento procesador y generan una respuesta o salida. La salida del PE (axón) se puede conectar a las entradas de otras neuronas artificiales mediante conexiones con una eficacia similar a la sinapsis de las conexiones neuronales del cerebro. Los PE están organizados en una serie de niveles que se denominan capas. El conjunto de estas capas forman una ANN.
En las ANN existen 2 capas con conexiones con el exterior. Una capa de entrada o buffer de entrada, donde se presentan los datos a la red, y una capa de salida que devuelve al exterior la respuesta de la red a una entrada concreta. Existen, además, una serie de capas intermedias que se denominan capas ocultas . Al igual que en los seres humanos, el aprendizaje que se produce en las máquinas, es una función que tiene una base estructural en este tejido nervioso artificial conformado por las ANN.Figura 1
Existen 2 tipos de métodos que permiten el aprendizaje de una máquina. El primero de ellos se llama «aprendizaje con datos supervisados» y requiere la participación de un humano que determina las relaciones correctas e incorrectas que adquiere la máquina. La función del humano es etiquetar y categorizar los datos de entrada y establecer un algoritmo de toma de decisiones para generar las diferentes salidas. Con el suficiente entrenamiento, la máquina será capaz de determinar la categoría de salida de un nuevo dato de entrada. El segundo método es el «aprendizaje automático o machine learning». Consiste en dotar de experiencia a la máquina y que sea ella misma, mediante una serie de normas lógicas iniciales, la que sea capaz de ir aprendiendo de manera independiente a partir de la experiencia que le proporcionan los datos y sin el concurso continuado de un humano. Para ello son necesarios algoritmos iniciales y un pequeño entrenamiento supervisado. Mientras que, en el aprendizaje supervisado, el conocimiento se hace explícito en forma de reglas, en la computación neuronal las ANN generan sus propias reglas aprendiendo de los ejemplos que se les muestran en la fase de entrenamiento. Una vez que las decisiones correctas alcanzan un número válido dentro del total de decisiones tomadas, conectamos este sistema inteligente a un sistema de big data para que esas experiencias afiancen los sistemas de toma de decisiones (aprendizaje).


- ANTECEDENTES

Aunque todo este campo de la informática es innovador en algunos aspectos, tiene antecedentes en los años 40 del siglo XX. En 1943, el neurobiólogo Warren McCulloch y el estadístico Walter Pitss, publicaron un artículo que definía que los eventos neuronales y las relaciones entre ellos pueden tratarse mediante la lógica proposicional. De esta manera se conforma la base y el inicio del desarrollo de la IA tal y como hoy la concebimos.
Pero no fue hasta una década más tarde, en 1956, cuando se celebró la primera Conferencia de Inteligencia Artificial en Darmouth que es considerada como la primera referencia seria a las redes neuronales artificiales. En esta conferencia se presentó la lógica teórica (Minsky, McCarthy, Rochester y Shannon) que es considerado el primer programa informático para solucionar problemas de búsqueda heurística.
En 1957 se presentó «Perceptron» el primer sistema capaz de identificar patrones geométricos, y en 1959 «Adaline» (Adaptive Linear Neuron) que fue utilizada con diferentes aplicaciones como reconocimiento de voz y caracteres, predicción del tiempo, y en el desarrollo de filtros para eliminar ecos de las líneas telefónicas.
A partir de estos trabajos la comunidad científica tuvo una percepción muy optimista de lo que la IA podría ofrecer, pero a mediados de la década de los 60 se comenzaron a publicar estudios críticos sobre la falta de aplicabilidad de la computación neuronal. Durante los años 70 y 80 pocos investigadores continuaron con esta línea de desarrollo científico (James Anderson, Teuvo Kohonen o Stephen Grossberg).
En 1982 John Hopfield crea el algoritmo Backpropagation que presenta un sistema neuronal formado por elementos procesadores interconectados que tienden a un mínimo de energía. Este hecho supuso volver a confiar en las posibilidades de la IA que en las últimas décadas ha tenido un avance exponencial.
Actualmente existen muchos investigadores en diferentes universidades que están realizando trabajos en el área de las redes neuronales artificiales en grupos multidisciplinares (informáticos, matemáticos, neurólogos, psicólogos del conocimiento, físicos, programadores o filósofos de la ciencia) que ofrecen nuevas e innovadoras perspectivas en esta área del conocimiento.


- INTELIGENCIA ARTIFICIAL Y ROBÓTICA

La palabra «robot» procede la palabra checa «robota» que significa «trabajo duro».
Podemos clasificar los robots en diferentes tipos:1.No mecánicos: La salida es una acción no mecánica como mostrar una información o mantener una conversación con el usuario humano. Entre ellos destacan los robots cuya interfaz es un sistema conversacional ya sea escrito o hablado («chatbots») con grandes aplicaciones actualmente como asistentes virtuales.2.Mecánicos: Utilizados generalmente en la industria. Hay de varios tipos:1.Androides: Apariencia humanoide.2.Zoomórficos: Apariencia animal.3.Móviles o rodantes: Transporte de cosas o personal.4.Poliarticulados: Industriales.
La apariencia humana de los robots ha dado lugar a la denominada «teoría del valle inquietante». «Lo inquietante» tiene su origen como concepto, en el año 1906 por Ernst Jentsch y se explica como una sensación perturbadora ante algo que nos es y no familiar al mismo tiempo. Una situación u objeto que se parece mucho a algo cotidiano, que conocemos bien pero que nos genera una sensación de cierta ansiedad o malestar sin que podamos explicar el motivo.
Esta teoría de lo inquietante se retoma en 1970 por Masahiro Mori para describir la relación entre los robots y los humanos. La relación es cada vez más positiva siempre y cuando el robot mantenga apariencia de robot y seamos conscientes de que se trata de una máquina. Cuando el robot va adquiriendo rasgos antropomórficos hasta llegar a presentar aspecto humano, la respuesta emocional del humano se irá haciendo cada vez más negativa hasta llegar a un punto de rechazo debido a la «inquietud» que genera .Figura 2
En la cultura occidental, sobre todo por la influencia cultural del cine, tenemos una imagen futurista de los robots como humanoides, cuando la realidad actual es otra, vivimos rodeados de IA y robótica. Así la Industria v.4.0 se fundamenta en la realidad virtual, la IA y el Internet de las cosas.
Los cobots o robots colaborativos fueron inventados en 1996 por J. Edward Colgate y Michael Peshkin, profesores en la Northwest University (Kirkland, Washington) como dispositivos robóticos que manipulan objetos en colaboración con un operador humano. Actualmente están dotados de IA para mejorar su rendimiento con la monitorización de numerosas variables como las condiciones del lugar de trabajo, visión artificial, identificación de patrones para predecir o detectar errores, pudiendo comunicar dicha información a otros cobots. Un sector que ha tenido un aumento de un 23% de 2017 a 2018, según la Federación Internacional de Robótica (IFR).
Ya tenemos robots funcionando para la realización de pruebas y análisis de laboratorio. Así en el Hospital Universitario de Copenhague, Gentofte (Dinamarca), un primer robot recoge la muestra de sangre y la coloca en un lector de códigos de barras. A continuación, una cámara de visión fotografía el color del tapón roscado e indica al robot que coloque la muestra en una de las 4 gradillas en función de su color. Luego un segundo robot recoge las muestras de las gradillas y las coloca en el alimentador de la máquina para su centrifugado y análisis. Estos robots manipulan alrededor de 3.000 muestras diarias (unos 7-8 tubos por minuto), lo que ha mejorado los tiempos de entrega de resultados.
Video: https://www.youtube.com/watch?v=mnk4iT4BTg4
Ya se están probando en pacientes tetrapléjicos exoesqueletos, unidades robóticas ponibles controladas por placas de computadora para alimentar un sistema de motores, neumáticos, palancas o sistemas hidráulicos para restaurar la locomoción. Han surgido como una nueva herramienta de rehabilitación en lesionados medulares. Sin embargo, todavía falta evidencia para respaldar su aplicación clínica teniendo en cuenta su alto coste.
La universidad de Brown está explorando con tecnología Intel® un proyecto de Interfaz Inteligente de Columna que tiene como objetivo utilizar la tecnología de IA para restaurar el movimiento y el control de la vejiga en pacientes con parálisis por lesiones graves de la médula espinal. Un equipo internacional de científicos ya ha utilizado una «interfaz cerebro-espinal» inalámbrica para evitar las lesiones de la médula espinal en un par de macacos Rhesus, restaurando el movimiento intencional de caminar en una pierna temporalmente paralizada.
La robótica en medicina no se limita a los ejemplos anteriores, las investigaciones en este campo se han dirigido a la asistencia a los pacientes y la asistencia o formación a los médicos. Así tenemos prótesis de miembros, electroestimulación, asistentes personales, robótica de rehabilitación, robótica quirúrgica, la formación médica con simuladores robotizados y los robots de almacenaje y distribución de medicamentos.
Desde los años 60, las prótesis de miembros han evolucionado constantemente, con distintos modelos para sustituir las primeras prótesis pasivas, todavía presentes en gran parte del mundo por su menor coste, por prótesis activas, las cuales por medio de medios mecánicos o sensores ubicados en alguna parte del cuerpo del paciente permiten mover por ejemplo una mano mecánica.
Hay distintos modelos y soluciones de prótesis de mano en continua evolución y mejora para aumentar su funcionalidad, como las 2 generaciones de manos DLR®, la TUAT/Karlsruhe®, la Blackfingers®, la mano robótica con mecanismo extensor, la mano compuesta de sensores propioceptivos o la mano Iowa® fruto de un trabajo de colaboración entre universidades americanas, españolas y suecas, entre otros.
En cuanto a la robótica quirúrgica también ha evolucionado progresivamente desde el primer procedimiento neuroquirúrgico asistido por un robot en 1985, donde se utilizó el robot industrial PUMA 560 (no diseñado para labores médicas) para introducir una guía para una biopsia cerebral. Posteriormente se empezaron a diseñar los primeros robots, puramente quirúrgicos, como asistentes del cirujano en operaciones de múltiples órganos y aparatos. Algunos modelos de robots quirúrgicos son: AESOP® (acrónimo de sistema endoscópico automatizado para un posicionamiento óptimo) empleado como asistente robótico controlado por voz para cirugía endoscópica, el robot estereotáctico NeuroMate® que es un sistema que se utiliza en centros neuroquirúrgicos para administrar tratamientos y realizar procedimientos de estimulación cerebral profunda, neuroendoscopia, estereoelectroencefalografía, biopsias e investigación; el extinto sistema robótico ZEUS® con el que se realizó la primera telecirugía del mundo en 2001, conocida como la operación Lindbergh, una exitosa colecistectomía laparoscópica de dos horas de duración, que se realizó en una paciente en un hospital de Estrasburgo, Francia, realizada por un equipo quirúrgico en Nueva York, EE. UU., el Sistema Robótico Quirúrgico Da Vinci® que en su versión más reciente, el sistema da Vinci Xi® permite una visión en 3D con un aumento de hasta 10 veces y elimina el temblor fisiológico, utilizándose principalmente en intervenciones de urología, cirugía general y ginecología oncológica, pero también en cirugía oral y maxilofacial, cirugía pediátrica, cirugía torácica o cirugía cardíaca; Probot®, diseñado para realizar prostatectomías, Robodoc® para cirugía ortopédica, Acrobot® para cirugía de rodilla y CyberKnife® sistema de radiocirugía robótica diseñado para tratar tumores ubicados en todo el cuerpo de manera no invasiva, entre otros.
El principal problema para su expansión es el alto coste de instalación y mantenimiento de los mismos, de ahí el desarrollo de sistemas más recientes y más asequibles, como por ejemplo:
La cirugía asistida por robot ha permitido avances en el campo quirúrgico como la cirugía a distancia y la cirugía mínimamente invasiva, junto a ventajas de precisión, incisiones más pequeñas, menor pérdida de sangre, disminución del dolor y tiempo de curación menor, lo que permite tratar un mayor número de pacientes con menor tiempo de hospitalización, haciendo que sea posible realizar intervenciones que de otro modo no serían viables.
La cirugía robótica presenta una serie de ventajas y de limitaciones respecto a la cirugía mínimamente invasiva convencional . Las ventajas suelen venir de explotar fortalezas complementarias entre humanos y dispositivos robóticos, como vemos resumido en la tabla 2.


- FINANCIACIÓN

Este artículo no ha recibido ningún tipo de ayuda o financiación de agencias del sector público, sector comercial o entidades sin ánimo de lucro.
